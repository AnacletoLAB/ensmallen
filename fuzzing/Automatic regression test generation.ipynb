{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_reader_model = \"\"\"let edges_reader = EdgeFileReader::new(\"{target_path}\")?\n",
    "        .set_rows_to_skip({rows_to_skip})\n",
    "        .set_header({header})\n",
    "        .set_separator({separator})?\n",
    "        .set_verbose({verbose})\n",
    "        .set_max_rows_number({max_rows_number})\n",
    "        .set_sources_column({sources_column})?\n",
    "        .set_sources_column_number({sources_column_number})?\n",
    "        .set_destinations_column({destinations_column})?\n",
    "        .set_destinations_column_number({destinations_column_number})?\n",
    "        .set_weights_column({weights_column})?\n",
    "        .set_weights_column_number({weights_column_number})?\n",
    "        .set_default_weight({default_weight})\n",
    "        .set_ignore_duplicates({ignore_duplicates})\n",
    "        .set_skip_selfloops({skip_selfloops})\n",
    "        .set_numeric_edge_type_ids({numeric_edge_type_ids})\n",
    "        .set_numeric_node_ids({numeric_node_ids})\n",
    "        .set_default_edge_type({default_edge_type}))\n",
    "        .set_skip_weights_if_unavailable({skip_weights_if_unavailable})\n",
    "        .set_skip_edge_types_if_unavailable({skip_edge_types_if_unavailable})\n",
    "        .set_edge_types_column({edge_types_column})?\n",
    "        .set_edge_types_column_number({edge_types_column_number})?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_reader_model = \"\"\"let nodes_reader = Some(NodeFileReader::new(\"{target_path}\")?\n",
    "        .set_rows_to_skip({rows_to_skip})\n",
    "        .set_separator({separator})?\n",
    "        .set_header({header})\n",
    "        .set_verbose({verbose})\n",
    "        .set_ignore_duplicates({ignore_duplicates})\n",
    "        .set_default_node_type({default_node_type})\n",
    "        .set_node_types_separator({node_types_separator})?\n",
    "        .set_nodes_column({nodes_column})?\n",
    "        .set_nodes_column_number({nodes_column_number})\n",
    "        .set_node_types_column({node_types_column})?\n",
    "        .set_node_types_column_number({node_types_column_number})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_node_reader_model = \"\"\"let nodes_reader = None;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_test_model = \"\"\"extern crate graph;\n",
    "\n",
    "use graph::{{{useful_imports}}};\n",
    "\n",
    "#[test]\n",
    "/// This is a regression test that has been automatically generated\n",
    "/// by the fuzzer harness.\n",
    "/// The test originally caused a panic in the file {filename},\n",
    "/// specifically (at the time) line {line_number} and column {column_number}.{message}\n",
    "///\n",
    "fn test_regression_{current_test_id}() -> Result<(), String> {{\n",
    "    {edges_reader}\n",
    "\n",
    "    {nodes_reader}\n",
    "\n",
    "    let mut graph = Graph::from_unsorted_csv(\n",
    "        edges_reader,\n",
    "        nodes_reader,\n",
    "        {directed}, // Directed\n",
    "        {directed_edge_list}, // Directed edge list\n",
    "        \"Fuzz Graph\" // Name of the graph\n",
    "    )?;\n",
    "    let _ = graph::test_utilities::default_test_suite(&mut graph, Some(false));\n",
    "    Ok(())\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(path:str)->Dict:\n",
    "    print(path)\n",
    "    with open(path, \"r\") as f:\n",
    "        return dict([\n",
    "            (line.strip().split(\",\", 1)[0], \"\")\n",
    "            if line.strip().split(\",\", 1)[1] == \"\"\n",
    "            else line.strip().split(\",\", 1)\n",
    "            for line in f.readlines()\n",
    "            if \",\" in line\n",
    "        ])\n",
    "\n",
    "def format_constructor(model, metadata_path, current_test_id, list_type) -> str:\n",
    "    if list_type not in (\"edges\", \"nodes\"):\n",
    "        raise ValueError(\"Given list type is not supported!\")\n",
    "    \n",
    "    # Move the new test edge list\n",
    "    target_path = os.path.join(\n",
    "        \"tests/data/regression/\"\n",
    "        \"{}.{}\".format(current_test_id, list_type)\n",
    "    )\n",
    "    \n",
    "    file_metadata = load_metadata(\n",
    "        metadata_path\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Remove all None values\n",
    "    simplified_model = \"\\n\".join([\n",
    "        line\n",
    "        for line in model.split(\"\\n\")\n",
    "        if not any(\n",
    "            \"set_{}(\".format(param) in line\n",
    "            for param, value in file_metadata.items()\n",
    "            if value == \"None\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    if list_type == \"nodes\":\n",
    "        simplified_model += \")\"\n",
    "    \n",
    "    simplified_model += \";\"\n",
    "        \n",
    "    return simplified_model.format(\n",
    "        target_path=target_path,\n",
    "        **file_metadata\n",
    "    ), target_path, file_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0218fae308da41fc8716af057e0a6672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building regression tests:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_tests/zkUlddbHQED9fznUaCYcWV9B9CCGTxZYjdHZyh7GBqGIUgA6tweS3g4ysdXdpNn3/graph_metadata.csv\n",
      "unit_tests/zkUlddbHQED9fznUaCYcWV9B9CCGTxZYjdHZyh7GBqGIUgA6tweS3g4ysdXdpNn3/panic.csv\n",
      "unit_tests/zkUlddbHQED9fznUaCYcWV9B9CCGTxZYjdHZyh7GBqGIUgA6tweS3g4ysdXdpNn3/edges_metadata.csv\n",
      "unit_tests/5dKB3S7sN8WYl2Ewo4yzyBZior192nQih88yePsP8eyofp6w1lGD7UmBOIgxc4Rr/graph_metadata.csv\n",
      "unit_tests/5dKB3S7sN8WYl2Ewo4yzyBZior192nQih88yePsP8eyofp6w1lGD7UmBOIgxc4Rr/panic.csv\n",
      "unit_tests/5dKB3S7sN8WYl2Ewo4yzyBZior192nQih88yePsP8eyofp6w1lGD7UmBOIgxc4Rr/edges_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "move = True\n",
    "\n",
    "\n",
    "os.makedirs(\"../graph/tests/data/regression\", exist_ok=True)\n",
    "for test_directory in tqdm(\n",
    "    glob(\"unit_tests/*\"),\n",
    "    desc=\"Building regression tests\"\n",
    "):\n",
    "    edges_path = os.path.join(\n",
    "        test_directory,\n",
    "        \"edges.edges\"\n",
    "    )\n",
    "    edges_metadata_path = os.path.join(\n",
    "        test_directory,\n",
    "        \"edges_metadata.csv\"\n",
    "    )\n",
    "    report_path = os.path.join(\n",
    "        test_directory,\n",
    "        \"report.txt\"\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(report_path):\n",
    "        report = open(report_path, \"r\").read()\n",
    "    else:\n",
    "        report = \"Report not provided\"\n",
    "    \n",
    "    graph_metadata = load_metadata(os.path.join(\n",
    "        test_directory,\n",
    "        \"graph_metadata.csv\"\n",
    "    ))\n",
    "    panic_path = os.path.join(\n",
    "        test_directory,\n",
    "        \"panic.csv\"\n",
    "    )\n",
    "    if not os.path.exists(panic_path):\n",
    "        continue\n",
    "    \n",
    "    panic_metadata = load_metadata(panic_path)\n",
    "    \n",
    "    usefull_imports = [\"Graph\", \"EdgeFileReader\"]\n",
    "    \n",
    "    has_node_file = any(\n",
    "        \"node\" in file\n",
    "        for file in os.listdir(test_directory)\n",
    "    )\n",
    "    \n",
    "    current_test_id = max([0, *[\n",
    "        int(test_name.split(\".\")[0])\n",
    "        for test_name in os.listdir(\"../graph/tests/data/regression\")\n",
    "    ]]) + 1\n",
    "    \n",
    "    if has_node_file:\n",
    "        usefull_imports.append(\"NodeFileReader\")\n",
    "        nodes_path = os.path.join(\n",
    "            test_directory,\n",
    "            \"nodes.nodes\"\n",
    "        )\n",
    "        nodes_metadata_path = os.path.join(\n",
    "            test_directory,\n",
    "            \"nodes_metadata.csv\"\n",
    "        )\n",
    "        nodes_reader, target_node_path, _ = format_constructor(\n",
    "            node_reader_model,\n",
    "            nodes_metadata_path,\n",
    "            current_test_id,\n",
    "            \"nodes\"\n",
    "        )\n",
    "        if move:\n",
    "            os.rename(\n",
    "                nodes_path,\n",
    "                os.path.join(\n",
    "                    \"../graph\",\n",
    "                    target_node_path\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        nodes_reader = default_node_reader_model\n",
    "\n",
    "    edges_reader, target_edge_path, metadata = format_constructor(\n",
    "        edge_reader_model,\n",
    "        edges_metadata_path,\n",
    "        current_test_id,\n",
    "        \"edges\"\n",
    "    )\n",
    "\n",
    "    if move:\n",
    "        os.rename(\n",
    "            edges_path,\n",
    "            os.path.join(\n",
    "                \"../graph\",\n",
    "                target_edge_path\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    regression_test = regression_test_model.format(\n",
    "        edges_reader=edges_reader,\n",
    "        nodes_reader=nodes_reader,\n",
    "        current_test_id=current_test_id,\n",
    "        filename=panic_metadata[\"file\"].split(os.sep)[-1].strip('\"'),\n",
    "        line_number=panic_metadata[\"line\"],\n",
    "        column_number=panic_metadata[\"col\"],\n",
    "        message=\"\" if \"message\" not in panic_metadata else \"\\n/// The provided message was: '{}'\".format(panic_metadata[\"message\"]),\n",
    "        useful_imports=\", \".join(usefull_imports),\n",
    "        report=report,\n",
    "        **graph_metadata\n",
    "    )\n",
    "    \n",
    "    with open(\"../graph/tests/test_regression_{}.rs\".format(current_test_id), \"w\") as f:\n",
    "        f.write(regression_test)\n",
    "    \n",
    "    if move:\n",
    "        shutil.rmtree(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../graph/tests/data/regression/100.edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cffae02df38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../graph/tests/data/regression/100.edges\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../graph/tests/data/regression/100.edges'"
     ]
    }
   ],
   "source": [
    "path = \"../graph/tests/data/regression/100.edges\"\n",
    "values = pd.read_csv(path, sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remap = list(set(values[[0, 1, 2]].values.flatten()))\n",
    "remapped_values = values.applymap(lambda x: remap.index(x) if x in remap else x)\n",
    "remapped_values.to_csv(path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
